{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaolaMaribel18/hands-on-2023A/blob/master/notebooks/11_introRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11 Recurrent Neural Networks\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are a class of artificial neural networks designed to process sequential data, where the order of data points matters. Unlike feedforward neural networks, RNNs have connections that form loops, allowing information to persist and be passed from one step to the next. This capability makes RNNs well-suited for tasks involving time series, natural language processing, speech recognition, video analysis, and more.\n",
        "\n",
        "By leveraging their recurrent connections and hidden state, RNNs excel at capturing temporal dependencies in sequential data. However, training RNNs effectively remains a challenge, particularly for long sequences. Various advanced RNN variants, such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), have been introduced to address the vanishing and exploding gradient problem and improve the modeling capabilities of RNNs for a wider range of applications."
      ],
      "metadata": {
        "collapsed": false,
        "id": "OhkfHODv0rZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Concepts of RNNs:\n",
        "1. _Recurrent Connections:_\n",
        "The defining feature of RNNs is the presence of recurrent connections, which allow information to be retained and propagated through time. In each step of the sequence, an RNN processes the current input along with the hidden state from the previous step, updating the hidden state accordingly. This feedback mechanism enables RNNs to learn dependencies and patterns across different time steps.\n",
        "2. _Hidden State:_\n",
        "The hidden state of an RNN acts as its memory and captures relevant information from the past. It is continuously updated at each time step and serves as an internal representation of the input sequence.\n",
        "3. _Training Challenges:_\n",
        "Training RNNs can be challenging due to the vanishing and exploding gradient problem. During backpropagation through time (BPTT), gradients can either become too small (vanish) or too large (explode), leading to poor convergence or training instability. This phenomenon occurs when the network has to propagate information over long sequences, and it becomes difficult for the gradients to accurately propagate back to the initial time steps."
      ],
      "metadata": {
        "collapsed": false,
        "id": "OaWsw-8r0rZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Architectures:\n",
        "There are different variations of RNN architectures, including Elman RNN, Jordan RNN, and bidirectional RNNs.\n",
        "1. _Elman RNN:_ In an Elman RNN, the hidden state is fed back to the network's input at the next time step, creating a simple feedback loop. This architecture is suitable for many sequential tasks but can suffer from vanishing gradients for long sequences.\n",
        "2. _Jordan RNN:_ In a Jordan RNN, the hidden state is fed back to the network's output at the current time step. This type of architecture can be useful for specific problems but is less commonly used compared to Elman RNNs and other more advanced RNN variants.\n",
        "3. _Bidirectional RNNs:_ Bidirectional RNNs process the input sequence in both forward and backward directions, allowing the model to consider future information as well. This is particularly useful for tasks where context from both past and future elements is essential, such as speech recognition and machine translation."
      ],
      "metadata": {
        "collapsed": false,
        "id": "0pwrNc560rZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "Use the IMDB movie reviews dataset to perform sentiment analysis with a simple RNN."
      ],
      "metadata": {
        "collapsed": false,
        "id": "vR5nD2FM0rZv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "6SILN2pE0rZw"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the IMDB movie reviews dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "VoxjD5rE0rZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "max_features = 5000  # Number of words to consider as features\n",
        "max_len_short = 100  # Maximum sequence length for short sequences\n",
        "max_len_long = 500   # Maximum sequence length for long sequences\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8tKB4FZ0rZy",
        "outputId": "ccffc446-9492-4ef8-abe8-f85d795e7855"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  Pad sequences to a fixed length for RNN input"
      ],
      "metadata": {
        "collapsed": false,
        "id": "p3Wn3mhP0rZy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "x_train_short = pad_sequences(x_train, maxlen=max_len_short)\n",
        "x_test_short = pad_sequences(x_test, maxlen=max_len_short)\n",
        "\n",
        "x_train_long = pad_sequences(x_train, maxlen=max_len_long)\n",
        "x_test_long = pad_sequences(x_test, maxlen=max_len_long)"
      ],
      "metadata": {
        "id": "QAjs19LY0rZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Build the RNN model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5G1157tM0rZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "def build_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 32))\n",
        "    model.add(SimpleRNN(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "9NAl_XgQ0rZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Train and evaluate the RNN model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "oOTVsnRb0rZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "    return loss, accuracy, history"
      ],
      "metadata": {
        "id": "wnWOONlc0rZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train and evaluate RNN on short and long sequences"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1d0g48oC0rZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training SimpleRNN model on short sequences:\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 10s 53ms/step - loss: 0.6689 - accuracy: 0.5857 - val_loss: 0.5671 - val_accuracy: 0.6954\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 0.4384 - accuracy: 0.8027 - val_loss: 0.3896 - val_accuracy: 0.8210\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 7s 46ms/step - loss: 0.3023 - accuracy: 0.8707 - val_loss: 0.3708 - val_accuracy: 0.8384\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 6s 40ms/step - loss: 0.2484 - accuracy: 0.8990 - val_loss: 0.3831 - val_accuracy: 0.8276\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 8s 48ms/step - loss: 0.2090 - accuracy: 0.9172 - val_loss: 0.3929 - val_accuracy: 0.8318\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3951 - accuracy: 0.8360\n",
            "\n",
            "Training SimpleRNN model on long sequences:\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 32s 194ms/step - loss: 0.6295 - accuracy: 0.6408 - val_loss: 0.4928 - val_accuracy: 0.7706\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 31s 195ms/step - loss: 0.4059 - accuracy: 0.8230 - val_loss: 0.4329 - val_accuracy: 0.8016\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 30s 192ms/step - loss: 0.3220 - accuracy: 0.8644 - val_loss: 0.3990 - val_accuracy: 0.8312\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 31s 197ms/step - loss: 0.3177 - accuracy: 0.8729 - val_loss: 0.4199 - val_accuracy: 0.8138\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 30s 189ms/step - loss: 0.3123 - accuracy: 0.8755 - val_loss: 0.3787 - val_accuracy: 0.8498\n",
            "782/782 [==============================] - 23s 30ms/step - loss: 0.3798 - accuracy: 0.8491\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining SimpleRNN model on short sequences:\")\n",
        "rnn_model_short = build_rnn_model()\n",
        "loss_short, accuracy_short, history_short = train_and_evaluate_model(\n",
        "    rnn_model_short, x_train_short, y_train, x_test_short, y_test\n",
        ")\n",
        "\n",
        "print(\"\\nTraining SimpleRNN model on long sequences:\")\n",
        "rnn_model_long = build_rnn_model()\n",
        "loss_long, accuracy_long, history_long = train_and_evaluate_model(\n",
        "    rnn_model_long, x_train_long, y_train, x_test_long, y_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNGa31ht0rZ1",
        "outputId": "0ea1aab7-62cb-4804-99d9-38ea10d39635"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compare the results"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7hvXGu0E0rZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results on Short Sequences:\n",
            "Loss: 0.3951, Accuracy: 0.8360\n",
            "\n",
            "Results on Long Sequences:\n",
            "Loss: 0.3798, Accuracy: 0.8491\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nResults on Short Sequences:\")\n",
        "print(f\"Loss: {loss_short:.4f}, Accuracy: {accuracy_short:.4f}\")\n",
        "\n",
        "print(\"\\nResults on Long Sequences:\")\n",
        "print(f\"Loss: {loss_long:.4f}, Accuracy: {accuracy_long:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64R6Y0YK0rZ2",
        "outputId": "7dc67472-c473-4e3e-e098-11fc7abb5d1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison between the results on short and long sequences should illustrate the challenges of training RNNs. You should observe that the RNN performs relatively well on short sequences but may struggle to generalize effectively on long sequences. This is due to the vanishing/exploding gradient problem.\n",
        "\n",
        "The vanishing gradient problem occurs when the gradients become very small as they propagate through time steps during training. Consequently, the model cannot learn long-term dependencies effectively, which negatively impacts performance on long sequences. On the other hand, the exploding gradient problem results in extremely large gradients, causing training instability.\n",
        "\n",
        "You should experiment further by adjusting the sequence lengths, training epochs, and other hyperparameters to observe how the performance changes and to see the impact of the vanishing/exploding gradient issues more clearly."
      ],
      "metadata": {
        "collapsed": false,
        "id": "qfnuWfq20rZ3"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}