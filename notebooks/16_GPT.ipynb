{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaolaMaribel18/hands-on-2023A/blob/master/notebooks/16_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16 GPT: Generative Pre-trained Transformer\n",
        "\n",
        "GPT is a model and approach developed by OpenAI. It is primarily known for its capabilities in generating coherent and contextually relevant text over long passages.\n",
        "\n",
        "* Architecture: GPT is based on the Transformer architecture. Unlike some other models that use both an encoder and a decoder, GPT exclusively utilizes the decoder part of the Transformer for its tasks.\n",
        "* Pre-training and Fine-tuning:\n",
        "    - Pre-training: GPT is first pre-trained on a large corpus of text (like books, articles, websites, etc.). During this phase, it learns to predict the next word in a sentence. This process enables the model to learn grammar, facts about the world, reasoning abilities, and even some level of common sense.\n",
        "    - Fine-tuning: After pre-training, the model can be fine-tuned on a specific task, such as translation, question-answering, or summarization, using a smaller, task-specific dataset.\n",
        "\n",
        "* Autoregressive Nature: GPT generates text in an autoregressive manner. This means it produces one word at a time and uses what it's generated so far as a context to generate the next word.\n",
        "\n",
        "#### Key Features:\n",
        "\n",
        "* Generative Abilities: As the name suggests, GPT excels at generating text. It can produce text that is often indistinguishable from what a human might write.\n",
        "* Few-Shot Learning: Introduced with GPT-3, this capability allows the model to perform tasks even when provided with very few examples (sometimes as few as one). By just specifying a task in natural language, GPT-3 can often understand and perform the task without explicit fine-tuning.\n",
        "* Versatility: Unlike many models that are trained for a specific task, GPT models, especially GPT-3, are versatile and can handle a wide range of tasks without task-specific training. This includes writing essays, answering questions, creating poetry, generating code, and much more.\n",
        "\n",
        "#### Versions:\n",
        "\n",
        "* GPT: The original model introduced by OpenAI.\n",
        "\n",
        "* GPT-2: A larger and more powerful version that garnered significant attention due to its impressive text generation capabilities. OpenAI initially withheld the fully-trained model due to concerns about misuse, but later released it given the broader community's responsible usage.\n",
        "\n",
        "* GPT-3: The third iteration with 175 billion parameters, making it one of the largest models ever created. It introduced the concept of few-shot and zero-shot learning, further advancing the state-of-the-art in various NLP tasks."
      ],
      "metadata": {
        "collapsed": false,
        "id": "9d4EX-LiyiIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Exploring Creative Writing with GPT\n",
        "\n",
        "Your task is to use OpenAI's GPT model to generate creative content. You'll explore various prompts and settings to see how GPT responds and creates different outputs."
      ],
      "metadata": {
        "collapsed": false,
        "id": "x405mNJ0yiIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load GPT-2 Model and Tokenizer. GPT-2 is freely available in Hugging Face's model hub and is still highly effective."
      ],
      "metadata": {
        "collapsed": false,
        "id": "F_GIr1GAyiIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBEaZfGE2baX",
        "outputId": "0ee5ed58-3b7b-4d57-f0a1-64d406d17ba5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "vFbTmLeT5qT_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "VgwM-HuqyiIP"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2-medium'  # You can start with 'gpt2' (smaller) and then experiment with larger models\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Creative Content Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "jfkikpF1yiIR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "source": [
        "def generate_creative_content(prompt, max_length=150, temperature=1.0):\n",
        "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "CmM_UhT6yiIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment:\n",
        "Use various prompts and observe GPT's creative capabilities.\n",
        "Change parameters like *max_length* and *temperature* to see their impact. (Note: A higher temperature value makes output more random, while a lower value makes it more deterministic.)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "m7XfmnZRyiIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Once upon a time, in a kingdom far away,\n",
            " there lived a king who was a great warrior. He was a great warrior, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king. He was a great king, and he was a great king\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: In a dystopian future, where AI rules the world,\n",
            " the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where AI rules the world, and the only way to survive is to become a cyborg.\n",
            "\n",
            "The game is set in a dystopian future where\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: The last dinosaur on Earth was not like the others. It\n",
            " was a giant, bipedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadrupedal, quadruped\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: Deep beneath the ocean waves, a secret civilization\n",
            " has been building a vast network of underground tunnels. The tunnels are filled with powerful weapons and technology, and are guarded by powerful creatures.\n",
            "\n",
            "The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel. The player is tasked with finding a way to infiltrate the Brotherhood's underground network, and to stop the Brotherhood from destroying the world.\n",
            "\n",
            "The game is set in the same universe as the original Fallout 3, but with a few changes. The game is set in the year 2277, and the player is a member of the Brotherhood of Steel.\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompts = [\n",
        "    \"Once upon a time, in a kingdom far away,\",\n",
        "    \"In a dystopian future, where AI rules the world,\",\n",
        "    \"The last dinosaur on Earth was not like the others. It\",\n",
        "    \"Deep beneath the ocean waves, a secret civilization\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(generate_creative_content(prompt))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTPa7wvIyiIS",
        "outputId": "ca85c309-e741-430c-df65-1c5a5ea3c0b1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion and Analysis:\n",
        "- Analyze the quality of the generated text: coherence, relevancy, and creativity.\n",
        "- Discuss how different prompts influence the direction of the story.\n",
        "- Experiment with custom prompts to generate different genres of creative content (e.g., horror, sci-fi, romance)."
      ],
      "metadata": {
        "collapsed": false,
        "id": "J6A3eTYxyiIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consistency, Relevance and Creativity:**\n",
        "\n",
        "First Prompt: The quality of the generated text is fairly consistent with the premise of the fairy tale. However, as it develops, it becomes repetitive and lacks relevance and creativity. It appears that the model is \"padding\" the text with repetition and does not meaningfully advance the story.\n",
        "\n",
        "Second Prompt: The generated text shows consistency in the dystopian setting where AI rules the world. Relevance is present as the idea of becoming a cyborg to survive is addressed. However, creativity is limited, as the model repeats the premise several times without adding new elements to the story.\n",
        "\n",
        "Third Prompt: The initial text lacks coherence, as the model seems to get bogged down in repetition. The lack of relevance and creativity is evident, as the novelty of a final dinosaur is not explored in detail.\n",
        "\n",
        "Fourth Prompt: Although the beginning seems consistent with the premise of a secret civilization under the ocean, the text quickly drifts into a description of the game \"Fallout 3,\" indicating that the model has strayed from the expected direction. This demonstrates a lack of relevance and consistency. Creativity is absent, as the model repeats pre-existing information."
      ],
      "metadata": {
        "id": "Gz2zaHDhizHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different prompts influence the direction of the story.**\n",
        "\n",
        "As seen in the examples above, the model tends to repeat itself and to lose relevance and coherence when asked to continue the story without a clear stimulus."
      ],
      "metadata": {
        "id": "uRFgqHf8i9lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom prompts**"
      ],
      "metadata": {
        "id": "GSWdPrhojSig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"On a dark and stormy night,\",\n",
        "    \"In the year 3025, humanity discovered a way to travel through time,\",\n",
        "    \"Under the starry sky, two lonely souls met for the first time,\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(generate_creative_content(prompt))\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWY67R4Eg-om",
        "outputId": "f8a18677-9a79-40b8-f83c-986edfdfe736"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: On a dark and stormy night,\n",
            " the two men were walking along the road when they came across a man who was carrying a large bag. The man was carrying a large bag of marijuana.\n",
            "\n",
            "\"I was like, 'What is that?' He said, 'It's a bag of marijuana,'\" said the man, who asked not to be identified.\n",
            "\n",
            "The man said he was carrying the bag because he was worried about his son's safety.\n",
            "\n",
            "\"I was like, 'What are you doing? You're going to get arrested,'\" the man said.\n",
            "\n",
            "The man said he was walking with his son when he saw the man carrying the bag.\n",
            "\n",
            "\"I was like, 'What are you doing?\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: In the year 3025, humanity discovered a way to travel through time,\n",
            " and the first humans were born. The first humans were called the \"Firstborn\" and were born in the year 3025. The Firstborn were the first humans to be born in the year 3025.\n",
            "\n",
            "The Firstborn were the first humans to be born in the year 3025. The Firstborn were the first humans to be born in the year 3025.\n",
            "\n",
            "The Firstborn were the first humans to be born in the year 3025. The Firstborn were the first humans to be born in the year 3025.\n",
            "\n",
            "The Firstborn were the first humans to be born in the year 3025. The Firstborn were the first humans\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: Under the starry sky, two lonely souls met for the first time,\n",
            " and they were both lost.\n",
            "\n",
            "\"I'm sorry, I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry.\"\n",
            "\n",
            "\"I'm sorry\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "* Use a larger GPT-2 variant (gpt2-large or gpt2-xl) and compare the quality of outputs.\n",
        "* Incorporate user feedback loops, where after getting an initial piece of text, they can provide a follow-up prompt to continue or steer the story."
      ],
      "metadata": {
        "collapsed": false,
        "id": "Avve6QtzyiIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####GPT2-large"
      ],
      "metadata": {
        "id": "DIZjXY5_gv_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "model_name_l = 'gpt2-large'\n",
        "model_l = GPT2LMHeadModel.from_pretrained(model_name_l)\n",
        "tokenizer_l = GPT2Tokenizer.from_pretrained(model_name_l)"
      ],
      "metadata": {
        "id": "zER2NIvZyiIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_creative_content_l(prompt, max_length=150, temperature=1.0):\n",
        "    \"\"\"Generate creative content using GPT-2 based on a given prompt.\"\"\"\n",
        "\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer_l.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text\n",
        "    output = model_l.generate(input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode and print the generated text\n",
        "    generated_text = tokenizer_l.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "1fKJTg9v37Ke"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Once upon a time, in a kingdom far away,\",\n",
        "    \"In a dystopian future, where AI rules the world,\",\n",
        "    \"The last dinosaur on Earth was not like the others. It\",\n",
        "    \"Deep beneath the ocean waves, a secret civilization\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    user_feedback = \"\"\n",
        "    while not user_feedback.lower().startswith(\"exit\"):\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        generated = generate_creative_content_l(prompt)\n",
        "        print(generated)\n",
        "        user_feedback = input(\"Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt): \")\n",
        "        if user_feedback.lower() != \"exit\":\n",
        "            prompt += \" \" + user_feedback\n",
        "        print(\"-\" * 50)\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFxT4lpY4Qyw",
        "outputId": "2a106fa0-4b76-44c6-ecda-b13d18974232"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Once upon a time, in a kingdom far away,\n",
            " the king and queen were blessed with a beautiful baby girl. Ever since that day, the princess has been growing up in a world of magic and adventure. But one day, the king and queen are kidnapped by a band of thieves. Now, the princess must find her way home and save her kingdom.\n",
            "\n",
            "The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda. The game is set in a fantasy world where the player controls a young girl named Princess Zelda.\n",
            "--------------------------------------------------\n",
            "==================================================\n",
            "Prompt: In a dystopian future, where AI rules the world,\n",
            " the only way to survive is to become a super-soldier.\n",
            "\n",
            "The game is set in a future where the world is ruled by a super-intelligence called the AI. The AI is a powerful and intelligent being that has been created by the government to protect the world from the threat of a super-intelligence.\n",
            "\n",
            "The game is set in a dystopian future where the world is ruled by a super-intelligence called the AI. The AI is a powerful and intelligent being that has been created by the government to protect the world from the threat of a super-intelligence.\n",
            "\n",
            "The game is set in a dystopian future where the world is ruled by a super-intelligence called the\n",
            "--------------------------------------------------\n",
            "==================================================\n",
            "Prompt: The last dinosaur on Earth was not like the others. It\n",
            " was a giant, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked, long-necked\n",
            "--------------------------------------------------\n",
            "==================================================\n",
            "Prompt: Deep beneath the ocean waves, a secret civilization\n",
            " has been building a massive, underground city. The city is called the City of the Dead, and it is home to a mysterious race of undead. The city is a living, breathing, breathing city, and it is the only place in the world where the dead can live. The City of the Dead is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It is a living, breathing, breathing city. It\n",
            "Provide feedback or enter a follow-up prompt (type 'exit' to move to the next prompt): exit\n",
            "--------------------------------------------------\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####GPT2-xl"
      ],
      "metadata": {
        "id": "9MEYHHZ9g0uA"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}